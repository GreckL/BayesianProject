tau_simul = runif(n,min = -1,max = 1)
library("bayesmeta")
### 1 - Simulating data ###
n = 20
tau_simul = runif(n,min = -1,max = 1)
sigma_simul = runif(n,min = -.5,max = .5)
df_pooled <- data.frame("tau" = tau_simul,
"se"  = sigma_simul)
bg <- baggr(df_pooled, pooling = "full")
installed.packages("baggr")
bg <- baggr(df_pooled, pooling = "full")
library("baggr")
installed.packages("baggr")
installes.packages("baggr")
install.packages("baggr")
library("baggr")
library("baggr")
bg <- baggr(df_pooled, pooling = "full")
sigma_simul = runif(n,min = .5,max = 5)
df_pooled <- data.frame("tau" = tau_simul,
"se"  = sigma_simul)
bg <- baggr(df_pooled, pooling = "full")
rm(list=ls())
library("baggr")
library("bayesplot")
library("ggplot2")        # For fancy plotting
library("tidyverse")        # Data manipulation
library("rstan")
set.seed(12345)
s=20         # Number of simulations
nstud = 5   # Maximum number of studies
nstud = 8   # Maximum number of studies
nstud = 10   # Maximum number of studies
theta_simul <- c()
sigma_simul <- c()
MLE_est <- c()
MLE_mean <- c()
MLE_MSE <- c()
BAY_MSE <- c()
bg <- c()
BAY_tau <- c()
bg_mse <- c()
MSE_hat <- 0
MSE_BAY <- c()
theta_true <- 1
for (n in 2:nstud) {    # Number of studies (meta analysis so start from 2 up to nstud)
for (i in 1:s) {      # Number of simulations
set.seed(s)
for (t in 1:n) {    # Generator process (study-dependent)
sigma_simul[t] = runif(1,min = 0,max = 4*theta_true)
theta_simul[t] = rnorm(1,mean = theta_true,sd = sigma_simul[t])
}
# Frequentist
weighted_num = sum(theta_simul %*% sigma_simul)
weighted_dem = sum(sigma_simul)
MLE_est[i]<- weighted_num/weighted_dem#sum(theta_simul)
# Bayesian
df_pooled = data.frame("tau"= theta_simul,
"se" = sigma_simul)
## Using partial pooling from Bayesian bagger
bg <- baggr(df_pooled, model="rubin", pooling = "partial")
# Extract the Stan fit object
fit_object <- bg$fit
# Get the summary table from the Stan fit object
fit_summary <- summary(fit_object)$summary
# Convert it to a data frame for easier manipulation
fit_summary_df <- as.data.frame(fit_summary)
# Get row names containing "theta_k"
theta_k_rows <- fit_summary_df[grep("theta_k", rownames(fit_summary)), ]
theta_SE <- (theta_k_rows$mean-1)^2
BAY_MSE <- sum(unlist(theta_SE))/n
MSE_hat = MSE_hat*((s-1)/s) + BAY_MSE*(1/s)
#*BAY_Nstud_MSE[i] <- sum(BAY_MSE)/n
# Print the theta_k rows
#print(theta_k_rows)
}
MLE_mean[n] <- sum(MLE_est)/s
MLE_MSE[n] <- (MLE_mean[n]-theta_true)^2
# bayesian
MSE_BAY[n] = MSE_hat
#tau_columns <- lapply(bg, function(df) df[["tau"]])
#BAY <- ba
#BAY_MSE[n] <- ((sum(unlist(tau_columns))/n)/s-theta_true)^2
#BAY_tau[i] <- hypermean(bg[i], transform = NULL,
#                        interval = 0.95,
#                        message = FALSE,
#                        summary = TRUE)
#bg_mse$n = (tau_columns[[n]]-1)^2
#BAY_MSE[n] = sum(unlist(bg_mse))/n
}
# Plot the MSEs to compare
df <- data.frame(x=1:nstud, MLE_MSE, MSE_BAY)
df_long <- df %>%
pivot_longer(cols = c(MLE_MSE, MSE_BAY), names_to = "Series", values_to = "Value")
# Plot with ggplot2
p <- ggplot(df_long, aes(x = x, y = Value, color = Series, group = Series)) +
geom_line(size = 1.2) +  # Add lines
geom_point(size = 3) +   # Add points
geom_text(aes(label = round(Value, 1)), vjust = -1, size = 3.5) +  # Add labels
theme_minimal() +        # Use a minimal theme
theme(
text = element_text(family = "Arial", size = 12),
plot.title = element_text(size = 16, face = "bold"),
legend.title = element_blank()
) +
labs(
title = "MSE Comparison in a Fixed Effects Setting",
x = "Number of Studies: n",
y = "MSE"
)
x11()
print(p)
print("MSE_BAY")
print(MSE_BAY)
install.packages("compiler")
library("compiler")
library(dplyr)
library(baggr)
library(compiler)
library(ggplot2)
rm(list=ls())
# Parameters
s <- 10         # Number of simulations
nstud <- 5      # Maximum number of studies
theta_true <- 1  # True fixed treatment effect
# Preallocate memory for results
MLE_mean <- numeric(nstud)
MLE_MSE <- numeric(nstud)
MSE_BAY <- numeric(nstud)
# Simulation Function
simulate_study <- function(n, theta_true, seed) {
set.seed(seed)
# Generate sigma and theta
sigma_simul <- runif(n, min = 0, max = 4 * theta_true)
theta_simul <- rnorm(n, mean = theta_true, sd = sigma_simul)
# Frequentist Weighted MLE
weighted_num <- sum(theta_simul * sigma_simul)
weighted_dem <- sum(sigma_simul)
MLE_est <- weighted_num / weighted_dem
# Bayesian Estimation with Baggr
df_pooled <- data.frame("tau" = theta_simul, "se" = sigma_simul)
bg <- baggr(df_pooled, model = "rubin", pooling = "partial")
fit_object <- bg$fit
fit_summary <- summary(fit_object)$summary
fit_summary_df <- as.data.frame(fit_summary)
theta_k_rows <- fit_summary_df[grep("theta_k", rownames(fit_summary)), ]
# Compute Mean Squared Error for Bayesian Estimation
theta_SE <- (theta_k_rows$mean - theta_true)^2
BAY_MSE <- mean(theta_SE)
list(MLE_est = MLE_est, BAY_MSE = BAY_MSE)
}
# Compile the function
compiled_simulate_study <- cmpfun(simulate_study)
# Initialize progress bar
pb <- txtProgressBar(min = 1, max = nstud, style = 3)
# Main Loop
for (n in 2:nstud) {
MLE_est <- numeric(s)
MSE_hat <- 0  # Reset Bayesian MSE accumulator
for (i in 1:s) {
results <- compiled_simulate_study(n, theta_true, i)
MLE_est[i] <- results$MLE_est
MSE_hat <- MSE_hat * ((s - 1) / s) + results$BAY_MSE / s
}
# Compute MSEs
MLE_mean[n] <- mean(MLE_est)
MLE_MSE[n] <- (MLE_mean[n] - theta_true)^2
MSE_BAY[n] <- MSE_hat
setTxtProgressBar(pb, n)
}
close(pb)
# Data Preparation for Plotting
df <- data.frame(
Number_of_Studies = 1:nstud,
Frequentist_MSE = MLE_MSE,
Bayesian_MSE = MSE_BAY
)
df_long <- df %>%
pivot_longer(cols = c(Frequentist_MSE, Bayesian_MSE),
names_to = "Approach",
values_to = "MSE")
# Plot with ggplot2
p <- ggplot(df_long, aes(x = Number_of_Studies, y = MSE, color = Approach, group = Approach)) +
geom_line(size = 1.2) +  # Add lines
geom_point(size = 3) +   # Add points
theme_minimal() +        # Use a minimal theme
theme(
text = element_text(family = "Arial", size = 12),
plot.title = element_text(size = 16, face = "bold"),
legend.title = element_blank()
) +
labs(
title = "MSE Comparison: Frequentist vs Bayesian",
x = "Number of Studies",
y = "Mean Squared Error"
)
# Display the plot
print(p)
rm(list=ls())
# Load required libraries
library(baggr)
library(compiler)
library(ggplot2)
library(dplyr)
# Parameters
s <- 1000         # Number of simulations
nstud <- 50      # Maximum number of studies
theta_true <- 1  # True fixed treatment effect
# Preallocate memory for results
MLE_mean <- numeric(nstud)
MLE_MSE <- numeric(nstud)
MSE_BAY <- numeric(nstud)
# Simulation Function
simulate_study <- function(n, theta_true, seed) {
set.seed(seed)
# Generate sigma and theta
sigma_simul <- runif(n, min = 0, max = 4 * theta_true)
theta_simul <- rnorm(n, mean = theta_true, sd = sigma_simul)
# Frequentist Weighted MLE
weighted_num <- sum(theta_simul * sigma_simul)
weighted_dem <- sum(sigma_simul)
MLE_est <- weighted_num / weighted_dem
# Bayesian Estimation with Baggr
df_pooled <- data.frame("tau" = theta_simul, "se" = sigma_simul)
bg <- baggr(df_pooled, model = "rubin", pooling = "partial")
fit_object <- bg$fit
fit_summary <- summary(fit_object)$summary
fit_summary_df <- as.data.frame(fit_summary)
theta_k_rows <- fit_summary_df[grep("theta_k", rownames(fit_summary)), ]
# Compute Mean Squared Error for Bayesian Estimation
theta_SE <- (theta_k_rows$mean - theta_true)^2
BAY_MSE <- mean(theta_SE)
list(MLE_est = MLE_est, BAY_MSE = BAY_MSE)
}
# Compile the function
compiled_simulate_study <- cmpfun(simulate_study)
# Initialize progress bar
pb <- txtProgressBar(min = 1, max = nstud, style = 3)
# Main Loop
for (n in 2:nstud) {
MLE_est <- numeric(s)
MSE_hat <- 0  # Reset Bayesian MSE accumulator
for (i in 1:s) {
results <- compiled_simulate_study(n, theta_true, i)
MLE_est[i] <- results$MLE_est
MSE_hat <- MSE_hat * ((s - 1) / s) + results$BAY_MSE / s
}
# Compute MSEs
MLE_mean[n] <- mean(MLE_est)
MLE_MSE[n] <- (MLE_mean[n] - theta_true)^2
MSE_BAY[n] <- MSE_hat
setTxtProgressBar(pb, n)
}
rm(list=ls())
# Load required libraries
library(baggr)
library(compiler)
library(ggplot2)
library(dplyr)
# Parameters
s <- 1000         # Number of simulations
nstud <- 50      # Maximum number of studies
theta_true <- 1  # True fixed treatment effect
# Preallocate memory for results
MLE_mean <- numeric(nstud)
MLE_MSE <- numeric(nstud)
MSE_BAY <- numeric(nstud)
# Simulation Function
simulate_study <- function(n, theta_true, seed) {
set.seed(seed)
# Generate sigma and theta
sigma_simul <- runif(n, min = 0, max = 4 * theta_true)
theta_simul <- rnorm(n, mean = theta_true, sd = sigma_simul)
# Frequentist Weighted MLE
weighted_num <- sum(theta_simul * sigma_simul)
weighted_dem <- sum(sigma_simul)
MLE_est <- weighted_num / weighted_dem
# Bayesian Estimation with Baggr
df_pooled <- data.frame("tau" = theta_simul, "se" = sigma_simul)
bg <- baggr(df_pooled, model = "rubin", pooling = "partial")
fit_object <- bg$fit
fit_summary <- summary(fit_object)$summary
fit_summary_df <- as.data.frame(fit_summary)
theta_k_rows <- fit_summary_df[grep("theta_k", rownames(fit_summary)), ]
# Compute Mean Squared Error for Bayesian Estimation
theta_SE <- (theta_k_rows$mean - theta_true)^2
BAY_MSE <- mean(theta_SE)
list(MLE_est = MLE_est, BAY_MSE = BAY_MSE)
}
# Compile the function
compiled_simulate_study <- cmpfun(simulate_study)
# Initialize progress bar
pb <- txtProgressBar(min = 1, max = nstud, style = 3)
# Main Loop
for (n in 2:nstud) {
MLE_est <- numeric(s)
MSE_hat <- 0  # Reset Bayesian MSE accumulator
for (i in 1:s) {
results <- compiled_simulate_study(n, theta_true, i)
MLE_est[i] <- results$MLE_est
MSE_hat <- MSE_hat * ((s - 1) / s) + results$BAY_MSE / s
}
# Compute MSEs
MLE_mean[n] <- mean(MLE_est)
MLE_MSE[n] <- (MLE_mean[n] - theta_true)^2
MSE_BAY[n] <- MSE_hat
setTxtProgressBar(pb, n)
}
rm(list=ls())
